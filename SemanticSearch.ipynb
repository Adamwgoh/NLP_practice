{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df3d47b5-3487-47d6-b2f8-248776dd5641",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:04:10.344170: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-30 20:04:10.960730: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-05-30 20:04:11.732730: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-30 20:04:11.751771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-30 20:04:11.751969: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                         Resume_str   \n",
       "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...  \\\n",
       "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
       "2  33176873           HR DIRECTOR       Summary      Over 2...   \n",
       "3  27018550           HR SPECIALIST       Summary    Dedica...   \n",
       "4  17812897           HR MANAGER         Skill Highlights  ...   \n",
       "\n",
       "                                         Resume_html Category  \n",
       "0  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "1  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "2  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "3  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "4  <div class=\"fontsize fontface vmargins hmargin...       HR  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "wn = WordNetLemmatizer()\n",
    "\n",
    "resume = pd.read_csv(\"archive/Resume/Resume.csv\")\n",
    "#resume = resume.reindex(np.random.permutation(resume.index))\n",
    "resume.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c398df99-8f92-491b-84dc-e8d5a7cdd5fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "def tokenize(input_doc):\n",
    "    tokens = []\n",
    "    wn = WordNetLemmatizer()\n",
    "    cptoken = [wn.lemmatize(x).lower() for x in word_tokenize(input_doc) if x not in stopwords and \\\n",
    "                 not x.isnumeric() and x.isalpha() and len(x) >= 2]\n",
    "        \n",
    "    return cptoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1280325b-9f2e-44b1-83fc-30f51a6a3ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arielg/anaconda3/envs/aistack/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_matrix shape: (2484, 32351)\n",
      "bow_matrix shape: (2484, 32351)\n",
      "[[1.         0.25575024 0.23616097 ... 0.09187018 0.10855762 0.09396372]\n",
      " [0.25575024 1.         0.20146724 ... 0.07162671 0.1392705  0.0711357 ]\n",
      " [0.23616097 0.20146724 1.         ... 0.0621186  0.09232892 0.08819255]\n",
      " ...\n",
      " [0.09187018 0.07162671 0.0621186  ... 1.         0.0711868  0.17859443]\n",
      " [0.10855762 0.1392705  0.09232892 ... 0.0711868  1.         0.06674726]\n",
      " [0.09396372 0.0711357  0.08819255 ... 0.17859443 0.06674726 1.        ]]\n",
      "cosine_sim shape: (2484, 2484)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize, analyzer=\"word\")\n",
    "bow_vectorizer = CountVectorizer(tokenizer=tokenize, analyzer=\"word\")\n",
    "\n",
    "corpus = resume.Resume_str\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "bow_matrix   = bow_vectorizer.fit_transform(corpus)\n",
    "print(f\"tfidf_matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"bow_matrix shape: {bow_matrix.shape}\")\n",
    "\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "bow_cosine_sim = cosine_similarity(bow_matrix, bow_matrix)t\n",
    "print(cosine_sim)\n",
    "print(f\"cosine_sim shape: {cosine_sim.shape}\")\n",
    "\n",
    "cosine_sim_lk = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7116ea26-009e-47ac-96ec-10280f8e52f9",
   "metadata": {},
   "source": [
    "## Utilizing TFIDF MAtrix for Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5348af3-cf52-4084-a92f-bfd17b701cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32351"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "888d8b4b-e276-4bd8-899e-8130f7c738bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2484/2484 [00:13<00:00, 181.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 34893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def inverted_index(words):\n",
    "    \"\"\"\n",
    "        An ivnerted index of words (given word, find docID and idx)\n",
    "    \"\"\"\n",
    "    inverted = {}\n",
    "    for idx, word in enumerate(words):\n",
    "        loc = inverted.setdefault(word, [])\n",
    "        loc.append(idx)\n",
    "    return inverted\n",
    "\n",
    "def inverted_index_add(inverted, docID, doc_idx):\n",
    "    for word in doc_idx.keys():\n",
    "        loc = doc_idx[word]\n",
    "        indices = inverted.setdefault(word, {})\n",
    "        indices[docID] = loc\n",
    "        \n",
    "    return inverted\n",
    "\n",
    "corpus = resume.Resume_str\n",
    "inverted_doc_idx = {}\n",
    "word_corpus = {}\n",
    "with tqdm(total=len(corpus)) as pbar:\n",
    "    for docid, x in enumerate(corpus):\n",
    "        words = tokenize(x)\n",
    "        word_corpus[docid] = words\n",
    "        inv_idx = inverted_index(words)\n",
    "        inverted_index_add(inverted_doc_idx, docid, inv_idx)\n",
    "        pbar.update(1)\n",
    "        \n",
    "data_frequency = {}\n",
    "for word in inverted_doc_idx.keys():\n",
    "    # number of docs that the word appear in\n",
    "    data_frequency[word] = len(list(inverted_doc_idx[word].keys()))\n",
    "    \n",
    "total_vocab_size = len(data_frequency)\n",
    "\n",
    "print(f\"total words: {total_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f046a5a6-67dd-46f4-9c91-099c0585bdc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03696502883983455"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [(k,v) for k,v in inverted_doc_idx['admin'].items()]\n",
    "adminidx = list(vectorizer.get_feature_names_out()).index('admin')\n",
    "tfidf_matrix[res[0][0], adminidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffc2da85-cb72-4fe3-99e0-e1cd419d5c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  60,   61,   87,  223,  224,  232,  259,  267,  289,  298,  316,\n",
      "        330,  521,  686,  702,  703,  741,  789,  935,  979,  991, 1115,\n",
      "       1147, 1153, 1195, 1232, 1286, 1378, 1420, 1537, 1574, 1577, 1579,\n",
      "       1584, 1608, 1656, 1687, 1768, 1815, 1843, 1861, 1863, 1916, 1999,\n",
      "       2159, 2242, 2325, 2395], dtype=int32), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0], dtype=int32))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'         DIRECTOR OF INFORMATION TECHNOLOGY       Executive Profile     Innovative executive and technology professional with strong work ethic and excellent communication skills, experienced in high-'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample search by hand and check\n",
    "# Get the feature name \"admin\" from the bow vector, look it up in the TF-IDF matrix, and pick up the first resume and check if it is relevant\n",
    "adminidx = list(vectorizer.get_feature_names_out()).index('admin')\n",
    "val = tfidf_matrix[:,adminidx].nonzero()\n",
    "print(val)\n",
    "tfidf_matrix[val[0], [adminidx]*len(val[0])]\n",
    "resume.Resume_str.iloc[273, ][:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1295537d-7b96-4038-9722-112740a2a22b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure you run the above to get your tfidf mat first as we refer it internally\n",
    "def ranked_search(query, firstx=10):\n",
    "    tokens = tokenize(query)\n",
    "    query_weights = {}\n",
    "    # get all the weights of the documents in which the term existed\n",
    "    #get documents that matches the key\n",
    "    for mapword, wmap in inverted_doc_idx.items():\n",
    "        appear_in_docs = list(wmap.keys())\n",
    "\n",
    "        if mapword in tokens:\n",
    "            # print(f\"looking via: {tokens}\")\n",
    "            # print(f\"found {mapword} in tokens for docs {appear_in_docs}\")\n",
    "            for docid in appear_in_docs:\n",
    "                wordidx = list(vectorizer.get_feature_names_out()).index(mapword)\n",
    "                tfidfval = tfidf_matrix[docid,wordidx]\n",
    "                # we add the value onto that doc id. The more words scored for that doc, the heavier the weight\n",
    "                query_weights[docid] = query_weights.get(docid,0) + tfidfval\n",
    "                \n",
    "    query_weights = sorted(query_weights.items(), key=lambda x:x[1], reverse=True)[:firstx]\n",
    "    result = []\n",
    "    for (docid, tfidfval) in query_weights:\n",
    "        data = {\n",
    "                    'Relevance': round(tfidfval*100,2),\n",
    "                    'ID': docid, \n",
    "                    'Resume_str': resume.Resume_str.iloc[docid], \n",
    "                    'Category': resume.Category[docid]\n",
    "                }\n",
    "        result.append(data)\n",
    "    result = pd.DataFrame(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38cbb604-fa96-4588-95bc-aebbcf00efb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.05 s, sys: 4.09 ms, total: 2.05 s\n",
      "Wall time: 2.05 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.90</td>\n",
       "      <td>4</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.87</td>\n",
       "      <td>101</td>\n",
       "      <td>REGIONAL HR BUSINESS PARTNER       Hu...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.10</td>\n",
       "      <td>58</td>\n",
       "      <td>HR CONSULTANT           Summary     C...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.76</td>\n",
       "      <td>92</td>\n",
       "      <td>GLOBAL HR MANAGER           Summary  ...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.55</td>\n",
       "      <td>85</td>\n",
       "      <td>SENIOR HR BUSINESS PARTNER           ...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>46.51</td>\n",
       "      <td>31</td>\n",
       "      <td>HR GENERALIST       Professional Prof...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46.18</td>\n",
       "      <td>68</td>\n",
       "      <td>HR DIRECTOR       Summary     HR Prof...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45.31</td>\n",
       "      <td>69</td>\n",
       "      <td>HR PROFESSIONAL       Summary     Dep...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42.35</td>\n",
       "      <td>88</td>\n",
       "      <td>REGIONAL HR DEPUTY MANAGER       Summ...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42.09</td>\n",
       "      <td>65</td>\n",
       "      <td>HR CONSULTING       Summary    7+ yea...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Relevance   ID                                         Resume_str Category\n",
       "0      58.90    4           HR MANAGER         Skill Highlights  ...       HR\n",
       "1      51.87  101           REGIONAL HR BUSINESS PARTNER       Hu...       HR\n",
       "2      51.10   58           HR CONSULTANT           Summary     C...       HR\n",
       "3      49.76   92           GLOBAL HR MANAGER           Summary  ...       HR\n",
       "4      46.55   85           SENIOR HR BUSINESS PARTNER           ...       HR\n",
       "5      46.51   31           HR GENERALIST       Professional Prof...       HR\n",
       "6      46.18   68           HR DIRECTOR       Summary     HR Prof...       HR\n",
       "7      45.31   69           HR PROFESSIONAL       Summary     Dep...       HR\n",
       "8      42.35   88           REGIONAL HR DEPUTY MANAGER       Summ...       HR\n",
       "9      42.09   65           HR CONSULTING       Summary    7+ yea...       HR"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time ranked_search(\"HR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e8398c-89be-43d0-b4a5-20ea25b1a13d",
   "metadata": {},
   "source": [
    "## Cosine similarity matrix of a corpus\n",
    "Cosine score is 0 (no similarity) and 1 (exact same)\n",
    "\n",
    "\n",
    "${sim(A,B)}$ = ${\\cos(\\theta)}$ = ${ {A\\cdot B} \\over ||A||||B|| }$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a78b5ed-2c73-4397-b062-5948ea13e233",
   "metadata": {},
   "source": [
    "## Cosine Similarity Check\n",
    "At this point, you can use the cosine similarity to check what are the documents that are most similar to based on the highest values in each row. To get a better value, you may use LSI (Latent Semantic Indexing) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11568f89-96d4-45d3-a887-7e5333ece477",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8224"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vectorizer.vocabulary_['director']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb778a6a-a087-48e9-a028-3193bfd721a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1.000000\n",
      "1803    0.348938\n",
      "187     0.328642\n",
      "1902    0.321385\n",
      "375     0.315933\n",
      "2116    0.313284\n",
      "1576    0.312016\n",
      "863     0.302114\n",
      "2318    0.299672\n",
      "1324    0.298496\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                HR\n",
       "1803    ENGINEERING\n",
       "187        DESIGNER\n",
       "1902     ACCOUNTANT\n",
       "375         TEACHER\n",
       "Name: Category, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with this, we can find documents that are closest to it and group them together\n",
    "\n",
    "# sorted_cosine_sim = pd.DataFrame(cosine_sim).apply(lambda x: np.argsort(x), axis=1, raw=True) \n",
    "# sorted_cosine_sim\n",
    "pd_cosine_sim = pd.DataFrame(cosine_sim)\n",
    "\n",
    "test_item = pd_cosine_sim.iloc[0]\n",
    "closest = np.argsort(test_item)[::-1]\n",
    "test_item_closest_val = test_item[closest][:10]\n",
    "print(test_item_closest_val)\n",
    "\n",
    "resume.Category[[0] + closest].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee664213-cd8d-4665-916d-78565a099e70",
   "metadata": {},
   "source": [
    "To compare a new file, we simply generate its BoW word vector and recompute the similarity matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
